{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering\n",
    "\n",
    "There are three datasets needed for this analysis. \n",
    "Firstly, the brand list is a catalog of all brands offered by Sephora. \n",
    "Next, we use the brand list and search for a detailed product list within each branch product_id like 'P07102'. \n",
    "Lastly, the product_id is then used in gathering the review data.\n",
    "\n",
    "Since there is already existing data parsed by Raghad Alharbi, we will skip Step 1 and Step 2.\n",
    "- Sephora result data from Kaggle: https://www.kaggle.com/raghadalharbi/all-products-available-on-sephora-website\n",
    "\n",
    "Tutorial for data gathering https://github.com/Shirleyiscool/Scraping-Sephora\n",
    "- Step1 Brand list: we will use requests to the website https://www.sephora.com/brands-list and parse a list of brands\n",
    "- Step2 Product list: for each brand list, we use requests to the individual website \"https://www.sephora.com\"+brand.a.attrs['href']+\"/all?pageSize=300\" and parse a list of products.\n",
    "- Step3 Review list: for each product, we use an API call to bazaarvoice and get all reviews under each product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional filters\n",
    "Due to large amount of products and reviews, we limited our scope according to the goal: look for products that brings happiness to people during pandemic. Thus below filters are applied.\n",
    "\n",
    "- Keep only product with review count > 50\n",
    "- Keep only product with review star >= 4\n",
    "- Keep only the most recent 3100 revies. (Certain product reviews are too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all packages are imported on top since we have to parse data in multiple days. \n",
    "# Thus the individual section has separate imports\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Brand list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getctime Response of \"brandlist\" Website from Sephora\n",
    "band_lst_link = \"https://www.sephora.com/brands-list\"\n",
    "response = requests.get(band_lst_link)\n",
    "\n",
    "# Use BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping brand links and save them into a list\n",
    "brand_link_lst = []\n",
    "main_box = soup.find_all(attrs={\"data-comp\": \"BrandsList StyledComponent BaseComponent \"})[0]\n",
    "for brand in main_box.find_all('li'):\n",
    "    brand_link_lst.append(\"https://www.sephora.com\" +\n",
    "                          brand.a.attrs['href']+\"/all?pageSize=300\")\n",
    "\n",
    "# Write brand links into a file:\n",
    "with open('data/brand_link.txt', 'w') as f:\n",
    "    for item in brand_link_lst:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "# Indicate scraping completion\n",
    "print(f'Got All Brand Links! There are {len(brand_link_lst)} brands in total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Product list\n",
    "\n",
    "In this step, we use the brand list to look for all products inside the brand. \n",
    "\n",
    "- In Step2.1, we gather all products from the brand page.\n",
    "- In Step2.1, we gather information regarding each product from the product page.\n",
    "\n",
    "### Step2.1: Get all products from brand list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_brand = 1\n",
    "test_product = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === 1 / 1 ===  acqua-di-parma === 143.198.222.22:8080Got All product Links! There are 12 products in total.\n"
     ]
    }
   ],
   "source": [
    "def scape_product(link, proxy=None):\n",
    "    \"\"\"\n",
    "    A function to scape all the product links from a given brand link.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(link, proxies={\n",
    "                                \"http\": proxy, \"https\": proxy}, timeout=15)\n",
    "    except:\n",
    "        print(f'\\r Unsuccessfully get data for {link.split(\"/\")[4]}', end=\"\")\n",
    "        return None\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    product_link_lst = []\n",
    "    try:\n",
    "        product_box = soup.find_all(attrs={\"data-comp\": \"ProductGrid \"})[0]\n",
    "    # There might be no products for that brand\n",
    "    except IndexError:\n",
    "        return []\n",
    "    for product in product_box.find_all('a',\n",
    "                                        attrs={\"data-comp\": \"ProductItem \"}):\n",
    "        # use function split to remove text like \"grid p12345\"\n",
    "        product_link_lst.append(\n",
    "            \"https://www.sephora.com\" + product.attrs['href'].split()[0])\n",
    "    return product_link_lst\n",
    "\n",
    "\n",
    "# Read brand links file\n",
    "product_link_dic = {'brand': [], 'product_links': []}\n",
    "# num_lines = sum(1 for line in open(\"data/brand_link.txt\", \"r\"))\n",
    "num_lines = test_brand\n",
    "\n",
    "# Scape all the product links from all the brands links.\n",
    "# This will take some time!\n",
    "ct = 1\n",
    "\n",
    "# Get proxies from http://www.freeproxylists.net/zh/?c=US&pr=HTTPS&u=80&s=ts\n",
    "px = ['143.198.222.22:8080', '143.198.206.183:8080', '157.230.208.88:8080']\n",
    "px_idx = 0\n",
    "\n",
    "for brand_link in open(\"data/brand_link.txt\", \"r\"):\n",
    "    if ct<=test_brand:\n",
    "        brand_name = brand_link.split('/')[4]\n",
    "        product_link_list = scape_product(brand_link[:-1], \n",
    "                                          #proxy=px[px_idx]\n",
    "                                         )\n",
    "        \n",
    "        # If one proxy does not work, use another\n",
    "        while product_link_list is None:\n",
    "            px_idx += 1\n",
    "            if px_idx == 3:\n",
    "                px_idx = 0\n",
    "            product_link_list = scape_product(brand_link[:-1], proxy=px[px_idx])\n",
    "\n",
    "        print(f'\\r === {ct} / {num_lines} ===  {brand_name} === {px[px_idx]}',\n",
    "              end=\"\")\n",
    "        product_link_dic['brand'] += [brand_name] * len(product_link_list)\n",
    "        product_link_dic['product_links'] += product_link_list\n",
    "        ct += 1\n",
    "\n",
    "# Write the result into csv file\n",
    "product_link_df = pd.DataFrame(product_link_dic)\n",
    "product_link_df.to_csv('data/product_links.csv', index=False)\n",
    "\n",
    "# Indicate scraping completion\n",
    "print(f'Got All product Links! There are {len(product_link_df)} products in '\n",
    "      f'total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2.2 Get details on product website\n",
    "For example, likes, review total, price, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001 / 12 || https://www.sephora.com/product/colonia-P163604?icid2=skugrid:p163604\n",
      "0002 / 12 || https://www.sephora.com/product/rosa-nobile-P388670?icid2=skugrid:p388670\n",
      "0003 / 12 || https://www.sephora.com/product/colonia-miniature-set-P443400?icid2=skugrid:p443400\n",
      "0004 / 12 || https://www.sephora.com/product/blu-mediterraneo-arancia-di-capri-P375388?icid2=skugrid:p375388\n",
      "0005 / 12 || https://www.sephora.com/product/blu-mediterraneo-minature-set-P443401?icid2=skugrid:p443401\n",
      "0006 / 12 || https://www.sephora.com/product/blu-mediterraneo-fico-di-amalfi-P307801?icid2=skugrid:p307801\n",
      "0007 / 12 || https://www.sephora.com/product/osmanthus-eau-de-parfum-P450175?icid2=skugrid:p450175\n",
      "0008 / 12 || https://www.sephora.com/product/blu-mediterraneo-bergamotto-di-calabria-P307802?icid2=skugrid:p307802\n",
      "0009 / 12 || https://www.sephora.com/product/peonia-nobile-P413669?icid2=skugrid:p413669\n",
      "0010 / 12 || https://www.sephora.com/product/acqua-di-parma-sakura-P456549?icid2=skugrid:p456549\n",
      "0011 / 12 || https://www.sephora.com/product/colonia-essenza-P269110?icid2=skugrid:p269110\n",
      "0012 / 12 || https://www.sephora.com/product/blu-mediterraneo-mandorlo-di-sicilia-P307803?icid2=skugrid:p307803\n"
     ]
    }
   ],
   "source": [
    "def get_data(product_link, px_list=None):\n",
    "    \"\"\"Get product information\"\"\"\n",
    "    data_dic = {'pd_id': [], 'size_and_item': [], 'category': [],\n",
    "                'price': [], 'love_count': [], 'reviews_count': []}\n",
    "    px_idx = 0\n",
    "    proxy = None if px_list is None else px_list[px_idx]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(product_link, \n",
    "                                    proxies={\"http\": proxy, \"https\": proxy}, \n",
    "                                    timeout=15)\n",
    "        except:\n",
    "            if px_idx == len(px_list) - 1:\n",
    "                px_idx = 0\n",
    "            else:\n",
    "                px_idx += 1\n",
    "            proxy = px_list[px_idx]\n",
    "            continue\n",
    "\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        data_dic['pd_id'] = re.findall(R'P[0-9]{3,6}', product_link)[0]\n",
    "\n",
    "        # Get Category\n",
    "        try:\n",
    "            cat_box = soup.find_all(attrs={'data-comp': 'ProductBreadCrumbs BreadCrumbs '})[0]\n",
    "            cat_list = [cat.string for cat in cat_box.find_all('a')]\n",
    "            category = ', '.join(cat_list)\n",
    "        except:\n",
    "            category = None\n",
    "\n",
    "\n",
    "        category\n",
    "\n",
    "        # Size and Content\n",
    "        try:\n",
    "            size_and_item = soup.find(\n",
    "                attrs={\"data-at\": \"sku_size_label\"}).get_text()\n",
    "        except:\n",
    "            size_and_item = None\n",
    "\n",
    "        size_and_item\n",
    "\n",
    "        # Get Price\n",
    "        try:\n",
    "            price = soup.find_all(attrs={'data-comp': 'Price '})[\n",
    "                0].get_text()\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        price\n",
    "\n",
    "\n",
    "        # Get love counts\n",
    "        try:\n",
    "            love_count = soup.find('span', attrs={\n",
    "                \"class\": \"css-jk94q9\"}).get_text()\n",
    "        except:\n",
    "            love_count = None\n",
    "\n",
    "        love_count\n",
    "\n",
    "\n",
    "        # review nums\n",
    "        try:\n",
    "        #     link_json = soup.find(attrs={\"id\": \"linkJSON\"})\n",
    "        #     json_str = str(link_json)\n",
    "        #     reviews = re.findall(R'\\\"reviews\\\":(.*?)\\,', json_str)\n",
    "            reviews = soup.find('span', attrs = {\n",
    "        #         'class':\"css-nv7myq eanm77i0\",\n",
    "#                 'class': \"css-1vj6vps eanm77i0\"\n",
    "        #         'data-comp' : 'StyledComponent BaseComponent ',\n",
    "        #         'id': 'ratings-reviews-container'\n",
    "                'data-at': 'number_of_reviews'\n",
    "            }).get_text()\n",
    "            reviews_count = reviews\n",
    "        except:\n",
    "            reviews_count = None\n",
    "\n",
    "\n",
    "        data_dic['category'] = category\n",
    "        data_dic['size_and_item'] = size_and_item\n",
    "        data_dic['love_count'] = love_count\n",
    "        data_dic['reviews_count'] = reviews_count\n",
    "        data_dic['price'] = price\n",
    "        break\n",
    "    return data_dic\n",
    "\n",
    "\n",
    "px_list_ = [\n",
    "            '167.99.218.191:8080',\n",
    "            '144.217.254.175:3128', \n",
    "            '165.225.77.47:9443',\n",
    "            '54.37.137.211:3128', \n",
    "            '165.22.91.197:8080',\n",
    "            '165.225.77.47:8800', \n",
    "            '165.225.77.47:9400',\n",
    "            '165.225.77.47:80', \n",
    "            '165.225.77.47:443',\n",
    "            '143.198.222.22:8080', \n",
    "            '143.198.206.183:8080', \n",
    "            '157.230.208.88:8080',\n",
    "            ]\n",
    "\n",
    "pd_links_df = pd.read_csv('data/product_links.csv')\n",
    "product_links = pd_links_df['product_links']\n",
    "\n",
    "result = []\n",
    "for i, link in enumerate(product_links[:test_product]):\n",
    "    result.append(get_data(link, px_list_))\n",
    "    pd_df = pd.DataFrame(result)\n",
    "    pd_df.to_csv('data/pd_info.csv', index=False)\n",
    "    print(f'{i + 1:04d} / {len(product_links)} || {link}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 22 10:51:37 2021 to Sat May 22 11:12:29 2021\n"
     ]
    }
   ],
   "source": [
    "print(start, 'to', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Product needs  1.67 mins\n"
     ]
    }
   ],
   "source": [
    "print('Per Product needs ', round(20/12,2), 'mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Total Time to scrape product list 278.33 hours\n"
     ]
    }
   ],
   "source": [
    "print('Estimated Total Time to scrape product list', round(1.67*10_000/60,2), 'hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Reviews\n",
    "\n",
    "From previous step, we already have all product_ids under each brand. In this section, we use these ids to get reviews.\n",
    "\n",
    "However, the speed is really slow in getting all product_ids. We then choose to use existing sephora_website_dataset.csv from Kaggle (parsed around April 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Getting the Reviews, we limited to the latest 3100 reviews.\n",
    "# In average, the \n",
    "print('Estimated Total Time', 60/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we could use the parsed csv from previous step.\n",
    "#pd_links_df = pd.read_parquet('./data/pd_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we used full data from Kaggle.\n",
    "# In the project, we also limited the products using the filters mentioned above.\n",
    "pd_links_df = pd.read_csv('./data/sephora_website_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>love</th>\n",
       "      <th>price</th>\n",
       "      <th>value_price</th>\n",
       "      <th>...</th>\n",
       "      <th>MarketingFlags</th>\n",
       "      <th>MarketingFlags_content</th>\n",
       "      <th>options</th>\n",
       "      <th>details</th>\n",
       "      <th>how_to_use</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>online_only</th>\n",
       "      <th>exclusive</th>\n",
       "      <th>limited_edition</th>\n",
       "      <th>limited_time_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2218774</td>\n",
       "      <td>Acqua Di Parma</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Blu Mediterraneo MINIATURE Set</td>\n",
       "      <td>5 x 0.16oz/5mL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3002</td>\n",
       "      <td>66.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>online only</td>\n",
       "      <td>no options</td>\n",
       "      <td>This enchanting set comes in a specially handc...</td>\n",
       "      <td>Suggested Usage:-Fragrance is intensified by t...</td>\n",
       "      <td>Arancia di Capri Eau de Toilette: Alcohol Dena...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2044816</td>\n",
       "      <td>Acqua Di Parma</td>\n",
       "      <td>Cologne</td>\n",
       "      <td>Colonia</td>\n",
       "      <td>0.7 oz/ 20 mL</td>\n",
       "      <td>4.5</td>\n",
       "      <td>76</td>\n",
       "      <td>2700</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>online only</td>\n",
       "      <td>- 0.7 oz/ 20 mL  Spray  - 1.7 oz/ 50 mL Eau d...</td>\n",
       "      <td>An elegant timeless scent filled with a fresh-...</td>\n",
       "      <td>no instructions</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1417567</td>\n",
       "      <td>Acqua Di Parma</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>Arancia di Capri</td>\n",
       "      <td>5 oz/ 148 mL</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26</td>\n",
       "      <td>2600</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>online only</td>\n",
       "      <td>- 1oz/30mL Eau de Toilette  - 2.5 oz/ 74 mL E...</td>\n",
       "      <td>Fragrance Family: Fresh Scent Type: Fresh Citr...</td>\n",
       "      <td>no instructions</td>\n",
       "      <td>Alcohol Denat.- Water- Fragrance- Limonene- Li...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1417617</td>\n",
       "      <td>Acqua Di Parma</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>Mirto di Panarea</td>\n",
       "      <td>2.5 oz/ 74 mL</td>\n",
       "      <td>4.5</td>\n",
       "      <td>23</td>\n",
       "      <td>2900</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>online only</td>\n",
       "      <td>- 1 oz/ 30 mL Eau de Toilette Spray - 2.5 oz/...</td>\n",
       "      <td>Panarea near Sicily is an an island suspended ...</td>\n",
       "      <td>no instructions</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2218766</td>\n",
       "      <td>Acqua Di Parma</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Colonia Miniature Set</td>\n",
       "      <td>5 x 0.16oz/5mL</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>943</td>\n",
       "      <td>72.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>online only</td>\n",
       "      <td>no options</td>\n",
       "      <td>The Colonia Miniature Set comes in an iconic A...</td>\n",
       "      <td>Suggested Usage:-Fragrance is intensified by t...</td>\n",
       "      <td>Colonia: Alcohol Denat.- Water- Fragrance- Lim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           brand   category                            name  \\\n",
       "0  2218774  Acqua Di Parma  Fragrance  Blu Mediterraneo MINIATURE Set   \n",
       "1  2044816  Acqua Di Parma    Cologne                         Colonia   \n",
       "2  1417567  Acqua Di Parma    Perfume                Arancia di Capri   \n",
       "3  1417617  Acqua Di Parma    Perfume                Mirto di Panarea   \n",
       "4  2218766  Acqua Di Parma  Fragrance           Colonia Miniature Set   \n",
       "\n",
       "             size  rating  number_of_reviews  love  price  value_price  ...  \\\n",
       "0  5 x 0.16oz/5mL     4.0                  4  3002   66.0         75.0  ...   \n",
       "1   0.7 oz/ 20 mL     4.5                 76  2700   66.0         66.0  ...   \n",
       "2    5 oz/ 148 mL     4.5                 26  2600  180.0        180.0  ...   \n",
       "3   2.5 oz/ 74 mL     4.5                 23  2900  120.0        120.0  ...   \n",
       "4  5 x 0.16oz/5mL     3.5                  2   943   72.0         80.0  ...   \n",
       "\n",
       "  MarketingFlags  MarketingFlags_content  \\\n",
       "0           True             online only   \n",
       "1           True             online only   \n",
       "2           True             online only   \n",
       "3           True             online only   \n",
       "4           True             online only   \n",
       "\n",
       "                                             options  \\\n",
       "0                                         no options   \n",
       "1   - 0.7 oz/ 20 mL  Spray  - 1.7 oz/ 50 mL Eau d...   \n",
       "2   - 1oz/30mL Eau de Toilette  - 2.5 oz/ 74 mL E...   \n",
       "3   - 1 oz/ 30 mL Eau de Toilette Spray - 2.5 oz/...   \n",
       "4                                         no options   \n",
       "\n",
       "                                             details  \\\n",
       "0  This enchanting set comes in a specially handc...   \n",
       "1  An elegant timeless scent filled with a fresh-...   \n",
       "2  Fragrance Family: Fresh Scent Type: Fresh Citr...   \n",
       "3  Panarea near Sicily is an an island suspended ...   \n",
       "4  The Colonia Miniature Set comes in an iconic A...   \n",
       "\n",
       "                                          how_to_use  \\\n",
       "0  Suggested Usage:-Fragrance is intensified by t...   \n",
       "1                                    no instructions   \n",
       "2                                    no instructions   \n",
       "3                                    no instructions   \n",
       "4  Suggested Usage:-Fragrance is intensified by t...   \n",
       "\n",
       "                                         ingredients online_only  exclusive  \\\n",
       "0  Arancia di Capri Eau de Toilette: Alcohol Dena...           1          0   \n",
       "1                                            unknown           1          0   \n",
       "2  Alcohol Denat.- Water- Fragrance- Limonene- Li...           1          0   \n",
       "3                                            unknown           1          0   \n",
       "4  Colonia: Alcohol Denat.- Water- Fragrance- Lim...           1          0   \n",
       "\n",
       "   limited_edition  limited_time_offer  \n",
       "0                0                   0  \n",
       "1                0                   0  \n",
       "2                0                   0  \n",
       "3                0                   0  \n",
       "4                0                   0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_links_df['product_links'] = pd_links_df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_products_already_downloaded(pd_links_df):\n",
    "    'Product reviews are too large (300 products for 600-800MB), thus we download in multiple batches.'\n",
    "    with open('data/product_keys.pkl', 'rb') as file:\n",
    "        lst = pickle.load(file)\n",
    "\n",
    "    pids_cleaned = lst\n",
    "    pids = list(result)\n",
    "    pd_links_df['key'] = pd_links_df['URL'].str.findall('P[0-9]{4,7}').apply(lambda x: x[0])\n",
    "    pd_links_df = pd_links_df[~pd_links_df['key'].isin(pids_cleaned)].copy()\n",
    "    \n",
    "    return pd_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip if this is the first time\n",
    "# pd_links_df = remove_products_already_downloaded(pd_links_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9168, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_links_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_product = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P443401: 9 reviews\n",
      "20.194.17.90:3128 || 0001/10\n",
      "P163604: 77 reviews\n",
      "20.194.17.90:3128 || 0002/10\n",
      "P375388: 33 reviews\n",
      "20.194.17.90:3128 || 0003/10\n",
      "P307804: 29 reviews\n",
      "20.194.17.90:3128 || 0004/10\n",
      "P443400: 4 reviews\n",
      "20.194.17.90:3128 || 0005/10\n",
      "P307801: 89 reviews\n",
      "20.194.17.90:3128 || 0006/10\n",
      "P388670: 87 reviews\n",
      "20.194.17.90:3128 || 0007/10\n",
      "P269110: 14 reviews\n",
      "20.194.17.90:3128 || 0008/10\n",
      "P444119: 8 reviews\n",
      "20.194.17.90:3128 || 0009/10\n",
      "P444120: 11 reviews\n",
      "20.194.17.90:3128 || 0010/10\n"
     ]
    }
   ],
   "source": [
    "# Add a column of product id\n",
    "pd_links_df['pd_id'] = [re.findall('P[0-9]{4,7}', link)[0] for link\n",
    "                        in pd_links_df['product_links']]\n",
    "\n",
    "pd_links_df = pd_links_df.iloc[:test_product,:].copy()\n",
    "\n",
    "def scrape_reviews(p_id, proxy=None):\n",
    "    url = 'https://api.bazaarvoice.com/data/reviews.json'\n",
    "    params = {\n",
    "        'Filter': f'ProductId:{p_id}',\n",
    "        'Sort': 'SubmissionTime:desc',\n",
    "        'Limit': 100,\n",
    "        'Offset': 0,\n",
    "        'Include': 'Products,Comments',\n",
    "        'Stats': 'Reviews',\n",
    "        'passkey': 'caQ0pQXZTqFVYA1yYnnJ9emgUiW59DXA85Kxry8Ma02HE',\n",
    "        'apiversion': 5.4,\n",
    "        'Locale': 'en_US',\n",
    "    }\n",
    "\n",
    "    \n",
    "    reviews = []\n",
    "    loop = 0\n",
    "\n",
    "    while loop<=30:\n",
    "        params['Offset'] = len(reviews)\n",
    "\n",
    "        # Make the same request that Javascript makes\n",
    "        try:\n",
    "            r = requests.get(url, params=params, proxies={\n",
    "                \"http\": proxy, \"https\": proxy}, timeout=15)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(f'{proxy} Cannot connect!')\n",
    "            return None, None\n",
    "        if loop == 0:\n",
    "            try:\n",
    "                product = r.json()['Includes']['Products']\n",
    "            except KeyError:\n",
    "                product = []\n",
    "\n",
    "        # break if we have an error or have all the reviews\n",
    "        if (r.status_code != 200) or (\n",
    "                len(reviews) >= r.json()['TotalResults']):\n",
    "            break\n",
    "\n",
    "        # add the list of results to current results\n",
    "        reviews.extend(r.json()['Results'])\n",
    "\n",
    "        # Give a pause, so we don't get blocked\n",
    "        time.sleep(0.2)\n",
    "        loop += 1\n",
    "\n",
    "    # Show how many reviews we scraped\n",
    "    print(f'{p_id}: {len(reviews)} reviews')\n",
    "    time.sleep(0.5)\n",
    "    return product, reviews\n",
    "\n",
    "\n",
    "# Scrape Product and Review Data\n",
    "# result already imported from file\n",
    "# result = {}\n",
    "\n",
    "proxies = [\n",
    "        '20.194.17.90:3128',\n",
    "        '69.167.174.17:80',\n",
    "        '129.226.52.93:443',\n",
    "        '164.90.222.95:80',\n",
    "        '143.55.38.198:8080',\n",
    "        '130.61.236.104:80',\n",
    "        '34.126.79.176:80',\n",
    "        '132.145.18.53:80',\n",
    "        '68.183.221.156:37486',\n",
    "        '143.198.196.205:80',\n",
    "        '140.227.63.136:58888',\n",
    "        '167.71.230.124:8080',\n",
    "        '148.66.131.212:80',\n",
    "        '173.249.38.220:8118',\n",
    "        '85.84.14.9:80',\n",
    "        '129.21.105.164:8080',\n",
    "        '190.9.55.12:8080',\n",
    "        '209.127.191.180:9279',\n",
    "        '208.74.51.100:80',\n",
    "        '159.65.174.145:3128',\n",
    "        '190.9.55.12:8080',\n",
    "        '45.95.96.187:8746',\n",
    "        '45.95.96.237:8796',\n",
    "        '45.94.47.66:8110',\n",
    "        '45.94.47.108:8152',\n",
    "        '45.95.99.226:7786',\n",
    "        '183.88.226.50:8080',\n",
    "        '52.151.15.4:80',\n",
    "        '51.81.82.175:80',\n",
    "        '129.21.158.30:8080',\n",
    "        '185.198.190.237:12444',\n",
    "        '149.125.70.236',\n",
    "        '167.99.118.98',\n",
    "        '92.204.129.161:80',\n",
    "        '52.168.34.113:80',\n",
    "        '74.205.128.201:80',\n",
    "        '209.97.150.167',\n",
    "        '191.96.42.80:8080',\n",
    "        '198.199.86.11:3128',\n",
    "        '198.199.86.11:3128',  \n",
    "]\n",
    "px_id = 0\n",
    "loop = 0\n",
    "\n",
    "for pid in pd_links_df['pd_id']:\n",
    "    loop_ = loop % 1000\n",
    "    if (loop_ < 900) and (loop_ >= 10):\n",
    "        product, reviews = None, None\n",
    "        while True:\n",
    "            if px_id == len(proxies):\n",
    "                px_id = 0\n",
    "\n",
    "            product_data, reviews_data = scrape_reviews(pid,\n",
    "                                                        proxy=proxies[px_id])\n",
    "            if product_data is not None:\n",
    "                break\n",
    "            px_id += 1\n",
    "\n",
    "    # Use my own server to connect\n",
    "    else:\n",
    "        product_data, reviews_data = scrape_reviews(pid)\n",
    "    loop += 1\n",
    "\n",
    "    print(f'{proxies[px_id]} || {loop:04d}/{len(pd_links_df)}')\n",
    "    result[pid] = [product_data, reviews_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.ctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 22 11:24:20 2021 to Sat May 22 11:24:43 2021\n"
     ]
    }
   ],
   "source": [
    "print(start, 'to', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9+77+33+29+4+89+87+14+8+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_review_time = 23/(9+77+33+29+4+89+87+14+8+11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06371191135734072"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_review_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_total_reviews = pd_links_df['number_of_reviews'].sum() * per_review_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2586652"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_links_df['number_of_reviews'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time needed for all reviews:  39.81 hours\n"
     ]
    }
   ],
   "source": [
    "print('Total time needed for all reviews: ', round(estimated_total_reviews/60/60, 2), 'hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/scraper_result.json\", \"w\") as file:\n",
    "    json.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/product_keys.pkl\", \"wb\") as file:\n",
    "    pickle.dump(list(result.values()), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backup file\n",
    "!cp ./data/scraper_result.json ./data/scraper_result.bak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
